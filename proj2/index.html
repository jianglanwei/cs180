<html>
<head>
    <title>David Wei's CS180 Project 2</title>
    <style>
        body {
            max-width: 960px;
            margin: 0 auto;
            padding: 0 16px;
        }
        h2 {text-align: center;}
        h3 {text-align: left;}
        h4 {text-align: left;}
        p {text-align: left;}
        div {text-align: center;}
        nav {text-align: right;}
        figure {
            padding: 4px;
            margin: auto;
        }
        figcaption {
            background-color: white;
            color: black;
            padding: 2px;
            text-align: center;
        }

    </style>
</head>

<body>
    <h2>
        <b>CS180-Proj2: Fun with Filters and Frequencies</b>
    </h2>
    <div>
        David Wei<br>
        <a href= "mailto: david_wei@berkeley.edu"> david_wei@berkeley.edu </a>
        <hr>
    <div>
    <nav>
    <nav>
        <a href="https://github.com/jianglanwei/cs180/tree/main/proj2/OfficialSpec.pdf">Official Spec</a>
        \
        <a href="https://github.com/jianglanwei/cs180/tree/main/proj2/code">My Code</a>
        \
        <a href="https://jianglanwei.github.io/cs180/">All CS180 Projects</a><br><br>
    </nav>
    </nav>
    
<section>
    <h3>
        1. Introduction
    </h3>
    <p>
        By applying filters and analyzing frequencies, images can be processed and combined in interesting ways.
        In the first part of this project, edge detection is conducted by applying the <b>Finite Difference Filter</b>. 
        <b>Gaussian Filter</b> is applied to get rid of the unnecessary wrinkles. 
        Then, images are sharpened by stacking its edges onto itself.
        The second part of this project consists of two image binding tasks. 
        The first task generates Hybrid Image by adding the high frequency of one image to the low frequency of another.
        Both successful and failing attempts are introduced.
        The second task blends images by applying the <b>Gaussian Stack</b> and the <b>Laplacian Stack</b>.
    </p>
</section>

<section>
    <h3>
        2. Edge Detection by Blurred Finite Difference
    </h3>
    <p>
        I detected the edges by applying the  <a href = "https://en.wikipedia.org/wiki/Finite_difference">Finite Difference</a> Filters <i>dx</i> and <i>dy</i>,
        denoted by <i>dx</i> = [1, -1], <i>dy</i> = [1, -1]^<i>T</i> respectively. 
        The horizontal and vertical edges are calculated by conducting convolution on the image using the filters, 
        and are combined into a single <b>edge image</b> using <a href="https://en.wikipedia.org/wiki/Euclidean_distance">Euclidean Distance</a>.
        To erase the wrinkles, I conducted <b>binaryzation</b> on the edge image. 
        Figure 1 shows the original <i>Cameraman</i> image and its horizontal, vertical and combined edge image before and after their binaryzation.
    </p>
        
    <figure>
        <img src="media/cameraman.png" alt="Figure 1a" width=42%, height=auto>
        <figcaption>Figure 1a: Original <i>Cameraman</i> image.</figcaption>
    </figure>

    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 6%><i>dx</i></td>
            <td width = 42%><figure>
                <img src="media/ver_edge.png" alt="Figure 1b" width=100%, height=auto>
                <figcaption>Figure 1c: Vertical edge image before binaryzation.</figcaption>
            </figure></td>
            <td width = 42%><figure>
                <img src="media/ver_edge_bin.png" alt="Figure 1b" width=100%, height=auto>
                <figcaption>Figure 1c: Vertical edge image after binaryzation.</figcaption>
            </figure></td>
        </tr>
    </table>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 6%><i>dy</i></td>
            <td width = 42%><figure>
                <img src="media/hor_edge.png" alt="Figure 1d" width=100%, height=auto>
                <figcaption>Figure 1d: Horizontal edge image before binaryzation.</figcaption>
            </figure></td>
            <td width = 42%><figure>
                <img src="media/hor_edge_bin.png" alt="Figure 1e" width=100%, height=auto>
                <figcaption>Figure 1e: Horizontal edge image after binaryzation.</figcaption>
            </figure></td>
        </tr>
    </table>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 6%>combined</td>
            <td width = 42%><figure>
                <img src="media/edge.png" alt="Figure 1f" width=100%, height=auto>
                <figcaption>Figure 1f: Combined edge image before binaryzation.</figcaption>
            </figure></td>
            <td width = 42%><figure>
                <img src="media/edge_bin.png" alt="Figure 1g" width=100%, height=auto>
                <figcaption>Figure 1g: Combined edge image after binaryzation.</figcaption>
            </figure></td>
        </tr>
    </table>
    <p>
        The edge image shown in Figure 1f contains unwanted noise.
        To remove the noise, I smoothed the original image by applying <a href = "https://en.wikipedia.org/wiki/Gaussian_filter">Gaussian Filter</a> 
        with a kernel size of 9 and a sigma of 1.5 before edge detection.
        The edge image produced this time is shown in Figure 2a. In another attempt, I generated a <b>Blurred Finite Difference Filter</b> by 
        conducting convolution on the <b>Gaussian Filter</b> and the two <b>Finite Difference Filters</b>, and applied the combined filters directly on the original image.
        The result of this second attempt is shown in Figure 2b.
    </p>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 50%><figure>
                <img src="media/edge_smoothed_uncombined_filter.png" alt="Figure 2a" width=100%, height=auto>
                <figcaption>Figure 2a: Noiseless edge image by applying Gaussian Filter before edge detection.</figcaption>
            </figure></td>
            <td width = 50%><figure>
                <img src="media/edge_smoothed_combined_filter.png" alt="Figure 2b" width=100%, height=auto>
                <figcaption>Figure 2b: Noiseless edge image by combining Gaussian Filter with Finite Difference Filters.</figcaption>
            </figure></td>
        </tr>
    </table>
    <p>
        The noiseless edge image obtained by the two attempts are almost identical.
    </p>
</section>

<section>
    <h3>
        3. Image Sharpening
    </h3>
    <p>
        <b>Image sharpening</b> can emphasize the details of the image, making the image "clearer" when observed by human eyes. 
        I sharpened the images using the <a href= "https://en.wikipedia.org/wiki/Unsharp_masking"> Unsharp Masking </a> technic. 
        First, a <b>Gaussian Filter</b> is applied to the target image to generate a blurred image, which contains the low frequency features of the image.
        Sigma in the Gaussian Filter is always set as 1/6 of the kernel size.
        Then, the high-frequency details are obtained by subtracting the low frequency features from the original image. 
        These details are emphasized in the final image by 
        \[
            IMG_{sharpened} = IMG_{original} + \alpha \times IMG_{high-frequency}.
        \]
        Figure 3, 4 shows the sharpening result of the <i>taj</i> and <i>forest</i> image.
    </p>

    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 50%><figure>
                <img src="media/taj.jpg" alt="Figure 3a" width=100%, height=auto>
                <figcaption>
                    Figure 3a: Original <i>taj</i> image.<br>
                    &nbsp;
                </figcaption>
            </figure></td>
            <td width = 50%><figure>
                <img src="media/taj_sharpened.jpg" alt="Figure 3b" width=100%, height=auto>
                <figcaption>
                    Figure 3b: Sharpened <i>taj</i> image.<br>
                    Gaussian kernel size = 7; alpha = 1
                </figcaption>
            </figure></td>
        </tr>
    </table>

    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 50%><figure>
                <img src="media/forest.jpg" alt="Figure 4a" width=100%, height=auto>
                <figcaption>
                    Figure 4a: Original <i>forest</i> image.<br>
                    &nbsp;
                </figcaption>
            </figure></td>
            <td width = 50%><figure>
                <img src="media/forest_sharpened.jpg" alt="Figure 4b" width=100%, height=auto>
                <figcaption>
                    Figure 4b: Sharpened <i>forest</i> image.<br>
                    Gaussian kernel size = 9; alpha = 1.5
                </figcaption>
            </figure></td>
        </tr>
    </table>


    <p>
        In order to evaluate my image sharpening approach, I took the <i>tiger</i> image, blurred it, and then sharpened it.
        The high frequency details lost in the blurring process should be restored.
        Figure 5 shows the result.
    </p>

    <figure>
        <img src="media/tiger.png" alt="Figure 5a" width=50%, height=auto>
        <figcaption>
            Figure 5a: Original <i>tiger</i> image.
        </figcaption>
    </figure>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 50%><figure>
                <img src="media/tiger_blurred.png" alt="Figure 5b" width=100%, height=auto>
                <figcaption>
                    Figure 5b: Blurred <i>tiger</i> image.<br>
                    Gaussian kernel size = 7
                </figcaption>
            </figure></td>
            <td width = 50%><figure>
                <img src="media/tiger_sharpened.png" alt="Figure 5c" width=100%, height=auto>
                <figcaption>
                    Figure 5c: Sharpened <i>blurred tiger</i> image.<br>
                    Gaussian kernel size = 15; alpha = 2
                </figcaption>
            </figure></td>
        </tr>
    </table>

    <p>
        The tiger in the sharpened image seems more vivid than the tiger in the blurred image.
        This indicates that a lower resolution image can show similar visual effects on human eyes using image sharpening.
    </p>

</section>

<section>
    <h3>
        4. Hybrid Images
    </h3>
    <p>
        Human eyes can only identify color changes in a range of frequencies. 
        When the colors change too swift or too slow on an image, humans can't identify the change.
        I combined two images by adding the low frequency features of one image and the high frequency details of the other.
        In this way, when looked afar, only the low frequency features from the first image would be noticed.
        When looked closely, only the high frequency details of the second image would be noticed.
        The following are three attempts of generating Hybrid Image.
    </p>
    <h4>
        4.1 Who is <i>Spiderman</i>? Take off your glasses!
    </h4>
    <p>
        By combining the high frequency details of <i>Spiderman</i> with mask on and the low frequency features of the face <i>Peter Parker</i> casted by <i>Tobey Maguire</i>,
        <i>Spiderman</i> should have mask on when looked closely. However, when look afar (or simply take off your nearsighted glasses like <i>Peter</i> did),
        <i>Spiderman</i> will reveal his true identity!
    </p>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 50%><figure>
                <img src="media/spiderman_high.jpg" alt="Figure 6a" width=100%, height=auto>
                <figcaption>
                    Figure 6a: <i>Spiderman</i> with mask on.<br>
                    Used as high frequency details; Gaussian kernel size = 13
                </figcaption>
            </figure></td>
            <td width = 50%><figure>
                <img src="media/spiderman_low.jpg" alt="Figure 6b" width=100%, height=auto>
                <figcaption>
                    Figure 6b: <i>Tobey Maguire</i> in <i>Spiderman</i> suit.<br>
                    Used as low frequency features; Gaussian kernel size = 17
                </figcaption>
            </figure></td>
        </tr>
    </table>
    <figure>
        <img src="media/spiderman_hybrid.jpg" alt="Figure 6c" width=50%, height=auto>
        <figcaption>
            Figure 6c: <i>Spiderman</i> hybrid image.
        </figcaption>
    </figure>
    <p>
        I analyzed the two <i>Spiderman</i> images in frequency domain before and after their filtering using <a href= "https://en.wikipedia.org/wiki/Fast_Fourier_transform"> Fast Fourier Transform</a>,
        Figure 7 shows the result.
    </p>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 50%><figure>
                <img src="media/spiderman_high_fft.jpg" alt="Figure 7a" width=100%, height=auto>
                <figcaption>
                    Figure 7a: High frequency image in frequency domain (before filtering).
                </figcaption>
            </figure></td>
            <td width = 50%><figure>
                <img src="media/spiderman_low_fft.jpg" alt="Figure 7b" width=100%, height=auto>
                <figcaption>
                    Figure 7b: Low frequency image in frequency domain (before filtering).
                </figcaption>
            </figure></td>
        </tr>
    </table>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 50%><figure>
                <img src="media/spiderman_high_fft_filtered.jpg" alt="Figure 7c" width=100%, height=auto>
                <figcaption>
                    Figure 7c: High frequency image in frequency domain (after filtering).
                </figcaption>
            </figure></td>
            <td width = 50%><figure>
                <img src="media/spiderman_low_fft_filtered.jpg" alt="Figure 7d" width=100%, height=auto>
                <figcaption>
                    Figure 7d: Low frequency image in frequency domain (after filtering).
                </figcaption>
            </figure></td>
        </tr>
    </table>
    <h4>
        4.2 <i>Wednesday</i> Cartoon/Real-Person Hybrid
    </h4>
    <p>
        I combined the high frequency details of the <i>Wednesday</i> cartoon version and the low frequency features of <i>Wednesday</i> casted by <i>Jenna Ortega</i>.
        The cartoon <i>Wednesday</i> should appear when looked closely, and the <i>Netfilx</i> <i>Wednesday</i> will appear when looked afar.
    </p>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 50%><figure>
                <img src="media/cartoon.jpg" alt="Figure 8a" width=100%, height=auto>
                <figcaption>
                    Figure 8a: <i>Wednesday</i> cartoon version.<br>
                    Used as high frequency details; Gaussian kernel size = 13
                </figcaption>
            </figure></td>
            <td width = 50%><figure>
                <img src="media/real.jpg" alt="Figure 8b" width=100%, height=auto>
                <figcaption>
                    Figure 8b: <i>Wednesday</i> starred by <i>Jenna Ortega</i>.<br>
                    Used as low frequency features; Gaussian kernel size = 17
                </figcaption>
            </figure></td>
        </tr>
    </table>
    <figure>
        <img src="media/wednesday_hybrid.jpg" alt="Figure 7c" width=50%, height=auto>
        <figcaption>
            Figure 8c: <i>Wednesday</i> hybrid image.
        </figcaption>
    </figure>
    <h4>
        4.3 <i>Golden Gate Bridge</i> History/Now Hybrid <a>(Failed)</a>
    </h4>
    <p>
        I combined the high frequency details of <i>Golden Gate Bridge</i> image filmed last century and the low frequency features of the bridge filmed recently.
        Figure 9 shows the result.
    </p>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 50%><figure>
                <img src="media/bridge_high.jpg" alt="Figure 9a" width=100%, height=auto>
                <figcaption>
                    Figure 9a: <i>Golden Gate Bridge</i> filmed last century.<br>
                    Used as high frequency details; Gaussian kernel size = 13
                </figcaption>
            </figure></td>
            <td width = 50%><figure>
                <img src="media/bridge_low.jpg" alt="Figure 9b" width=100%, height=auto>
                <figcaption>
                    Figure 9b: <i>Golden Gate Bridge</i> filmed recently.<br>
                    Used as low frequency features; Gaussian kernel size = 17
                </figcaption>
            </figure></td>
        </tr>
    </table>
    <figure>
        <img src="media/bridge_hybrid.jpg" alt="Figure 9c" width=50%, height=auto>
        <figcaption>
            Figure 9c: <i>Golden Gate Bridge</i> hybrid image.
        </figcaption>
    </figure>
    <p>
        The results are not satisfying as the older <i>Golden Gate Bridge</i> image can barely be seen even when looked closely.
        I believe this is because one of the photos are grayscale while the other is colored.
        It can be hard for a grayscale image to gain human eyes' attention when it is mixed with a colored image.
    </p>
    
<section>
    <h3>
        5. Multiresolution Blending
    </h3>
    <p>
        When blending two images together, it would seem more natural if the high-frequency patterns are not stacked together 
        while the low-frequency background color change gradually between the images. I implemented <b>Laplacian Stack</b>
        to obtain the image features under different frequencies. Laplacian Stack is calculated using the Gaussian Stack. 
        Each layer in the Gaussian Stack blurs the image from the last layer using the Gaussian Filter, 
        with an increasing larger kernel size as the layers go deep. The first layer in the Gaussian Stack is the original image.
        Each layer in the Laplacian Stack is denoted by
        \[
            lstack[i] = gstack[i] - gstack[i + 1];
        \]
        \[
            lstack[-1] = gstack[-1].
        \]
        Each layer in the Laplacian Stack contains a certain range of frequency, and should be blended in different ways. 
    </p>
    <p>
        The images are blended under the instruction of a <b>mask image</b>. Each layer is assigned with a blurred version of the mask image.
        The deeper the layer, the more blurred (using larger <b>Gaussian Filter</b>) the mask image is.
        First, a blend image for each layer is generated, denoted by 
        \[
        blend[i] = lstack1[i] * mask[i] + lstack2[i] * (1 - mask[i]).
        \]
        Then, the blended layers are added together, and the result is the blending output.
    </p>
    <p>
        Figure 10 shows my attempt of blending the <i>apple</i> image (Figure 10a) and the <i>orange</i> image (Figure 10c) using mask image (Figure 10b).
        Figure 11 shows the Laplacian Stack of this process, where the left column is the Laplacian Stack of the <i>apple</i> image,
        the right column is the Laplacian Stack of the <i>orange</i> image, and the middle column is the blended layers.
        The blending output is shown in Figure 10d.
    </p>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 33%><figure>
                <img src="media/apple.png" alt="Figure 10a" width=100%, height=auto>
                <figcaption>
                    Figure 10a: <i>Apple</i> image.<br>
                    Blended from the left.
                </figcaption>
            </figure></td>
            <td width = 33%><figure>
                <img src="media/oraple_mask.png" alt="Figure 10b" width=100%, height=auto>
                <figcaption>
                    Figure 10b: Mask image.<br>
                    &nbsp;
                </figcaption>
            </figure></td>
            <td width = 33%><figure>
                <img src="media/orange.png" alt="Figure 10c" width=100%, height=auto>
                <figcaption>
                    Figure 10c: <i>Orange</i> image.<br>
                    Blended from the right.
                </figcaption>
            </figure></td>
        </tr>
    </table>
    <figure>
        <img src="media/oraple.png" alt="Figure 10d" width=50%, height=auto>
        <figcaption>
            Figure 10d: <i>Oraple</i> image.
        </figcaption>
    </figure>
    <figure>
        <img src="media/lstack.png" alt="Figure 11" width=75%, height=auto>
        <figcaption>
            Figure 11: Laplacian Stack of the <i>Oraple</i> image blending process.
        </figcaption>
    </figure>
    <p>
        I also blended earth and moon images to generate <i>moonearth</i> (imagine when human inhabits half of the moon),
        and blended my friend <i>Mike</i> and a kangaroo to generate <i>Mikaroo</i> (a scornful kangaroo). 
        The results are shown in Figure 12 and 13 respectively.
    </p>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 33%><figure>
                <img src="media/earth.jpg" alt="Figure 12a" width=100%, height=auto>
                <figcaption>
                    Figure 12a: Earth image.<br>
                    Blended from the top.
                </figcaption>
            </figure></td>
            <td width = 33%><figure> 
                <img src="media/moonearth_mask.png" alt="Figure 12b" width=100%, height=auto>
                <figcaption>
                    Figure 12b: Mask image.<br>
                    &nbsp;
                </figcaption>
            </figure></td>
            <td width = 33%><figure>
                <img src="media/moon.jpg" alt="Figure 12c" width=100%, height=auto>
                <figcaption>
                    Figure 12c: Moon image.<br>
                    Blended from the bottom.
                </figcaption>
            </figure></td>
        </tr>
    </table>
    <figure>
        <img src="media/moonearth.png" alt="Figure 12d" width=50%, height=auto>
        <figcaption>
            Figure 12d: <i>Moonearth</i> image.
        </figcaption>
    </figure>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 30%><figure>
                <img src="media/mike.jpg" alt="Figure 13a" width=100%, height=auto>
                <figcaption>
                    Figure 13a: Image of <i>Mike</i>.<br>
                    Contributed the scornful eyes.
                </figcaption>
            </figure></td>
            <td width = 30%><figure>
                <img src="media/mikaroo_mask.jpg" alt="Figure 13b" width=100%, height=auto>
                <figcaption>
                    Figure 13b: Mask image.<br>
                    &nbsp;
                </figcaption>
            </figure></td>
            <td width = 30%><figure>
                <img src="media/kangaroo.jpg" alt="Figure 13c" width=100%, height=auto>
                <figcaption>
                    Figure 13c: Image of a kangaroo.<br>
                    Contributed to all other parts except the eyes.
                </figcaption>
            </figure></td>
        </tr>
    </table>
    <figure>
        <img src="media/mikaroo.png" alt="Figure 13d" width=35%, height=auto>
        <figcaption>
            Figure 13d: A <b>scornful</b> kangaroo.
        </figcaption>
    </figure>
    <h4>
        Bells and Whistles
    </h4>
    <p>
        When trying different ways of recoloring the <i>moonearth</i> image, I accidentally used the <i>moonearth</i> image generated last time as the new mask image.
        The blending result is amazing. It looks like lunar surface, but has clouds and oceans. I cannot explain this phenomenon, but here is the image.
    </p>
    <table class="center" style="margin-left:auto;margin-right:auto;">
        <tr>
            <td width = 33%><figure>
                <img src="media/earth.jpg" alt="Figure 14a" width=100%, height=auto>
                <figcaption>
                    Figure 14a: Earth image.<br>
                    &nbsp;
                </figcaption>
            </figure></td>
            <td width = 33%><figure> 
                <img src="media/moonearth.png" alt="Figure 14b" width=100%, height=auto>
                <figcaption>
                    Figure 14b: Mask image (the blending result from last time).
                </figcaption>
            </figure></td>
            <td width = 33%><figure>
                <img src="media/moon.jpg" alt="Figure 14c" width=100%, height=auto>
                <figcaption>
                    Figure 14c: Moon image.<br>
                    &nbsp;
                </figcaption>
            </figure></td>
        </tr>
    </table>
    <figure>
        <img src="media/moonearth_ultra.png" alt="Figure 14d" width=50%, height=auto>
        <figcaption>
            Figure 14d: <i>Moonearth Ultra</i> image.
        </figcaption>
    </figure>


</section>



<p>* Finished on Sep 23, 2024.</p>

<div style="margin-top: 20px; font-size: 0.9em; color: #555; border-top: 1px solid #ccc; padding-top: 10px; text-align: left;">
  <strong>Disclaimer:</strong>  
  All materials, including assignments, documents, and source code, are provided solely for personal coursework.  
  All rights reserved by the UC Berkeley CS180 course staff. Redistribution or commercial use is strictly prohibited.
</div>

</body>

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</html>
